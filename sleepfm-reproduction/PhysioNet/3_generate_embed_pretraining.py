import os
import sys
import math
import pickle
import time
import datetime

import click
import torch
import tqdm
import numpy as np
from loguru import logger

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.append("/ssd/kdpark/sleepfm-codebase")

# ë‚´ë¶€ ëª¨ë“ˆ import
from config import (
    PATH_TO_PROCESSED_DATA,
    CHANNEL_DATA_IDS,
    EMBED_SAVE_PATH,
)
from sleepfm.model import models
from sleepfm.model.dataset import EventDataset as Dataset


@click.command("generate_eval_embed")
@click.argument("run_name", type=str)  # ì˜ˆ: my_run_final
@click.option(
    "--data_dir",
    type=str,
    default=None,
    help="ê²½ë¡œ: dataset_events_-1.pickle ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸: PATH_TO_PROCESSED_DATA)",
)
@click.option("--dataset_file", type=str, default="dataset_events_-1.pickle")
@click.option("--batch_size", type=int, default=32)
@click.option("--num_workers", type=int, default=2)
@click.option(
    "--splits",
    type=str,
    default="train,valid,test",
    help="ì‚¬ìš©í•  ë°ì´í„° split ë¦¬ìŠ¤íŠ¸. ì˜ˆ: 'train,valid,test' ë˜ëŠ” 'test'",
)
def generate_eval_embed(
    run_name,
    data_dir,
    dataset_file,
    batch_size,
    num_workers,
    splits,
):
    """
    RUN_NAME: outputs/RUN_NAME/ ì•ˆì˜ best.ptë¥¼ ì‚¬ìš©í•´
    ë°ì´í„°ì…‹ì—ì„œ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ê³ 
    outputs/RUN_NAME/eval_data/ ì— *_emb.pickle ì €ì¥.
    """

    # -----------------------
    # ê²½ë¡œ ì„¤ì •
    # -----------------------
    if data_dir is None:
        data_dir = PATH_TO_PROCESSED_DATA

    # EMBED_SAVE_PATHì—ì„œ outputs ë£¨íŠ¸ ì¶”ì¶œ
    # "/ssd/.../outputs/my_run/embeddings" -> "/ssd/.../outputs"
    outputs_root = os.path.dirname(os.path.dirname(EMBED_SAVE_PATH))

    # ì´ runì˜ ì²´í¬í¬ì¸íŠ¸/ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = os.path.join(outputs_root, run_name)

    logger.info(f"Data dir       : {data_dir}")
    logger.info(f"Dataset file   : {dataset_file}")
    logger.info(f"Outputs root   : {outputs_root}")
    logger.info(f"Run directory  : {output_dir}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # "train,valid,test" -> ["train","valid","test"]
    splits = [s.strip() for s in splits.split(",") if s.strip()]

    # -----------------------
    # Dataset ë¡œë“œ
    # -----------------------
    path_to_dataset_pickle = os.path.join(data_dir, dataset_file)

    dataset = {
        split: Dataset(
            path_to_dataset_pickle,
            split=split,
            modality_type=["respiratory", "sleep_stages", "ekg"],
        )
        for split in splits
    }

    # -----------------------
    # ëª¨ë¸ ì •ì˜ (config ê¸°ë°˜ ì±„ë„ ìˆ˜ ì‚¬ìš©)
    # -----------------------

    # Respiratory
    in_channel_resp = len(CHANNEL_DATA_IDS["Respiratory"])
    model_resp = models.EffNet(in_channel=in_channel_resp, stride=2, dilation=1)
    model_resp.fc = torch.nn.Linear(model_resp.fc.in_features, 512)

    # Sleep_Stages
    in_channel_sleep = len(CHANNEL_DATA_IDS["Sleep_Stages"])  # checkpoint ê¸°ì¤€ 5ì±„ë„
    model_sleep = models.EffNet(in_channel=in_channel_sleep, stride=2, dilation=1)
    model_sleep.fc = torch.nn.Linear(model_sleep.fc.in_features, 512)

    # EKG
    in_channel_ekg = len(CHANNEL_DATA_IDS["EKG"])
    model_ekg = models.EffNet(in_channel=in_channel_ekg, stride=2, dilation=1)
    model_ekg.fc = torch.nn.Linear(model_ekg.fc.in_features, 512)

    if device.type == "cuda":
        model_resp = torch.nn.DataParallel(model_resp)
        model_sleep = torch.nn.DataParallel(model_sleep)
        model_ekg = torch.nn.DataParallel(model_ekg)

    model_resp.to(device)
    model_sleep.to(device)
    model_ekg.to(device)

    # -----------------------
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    # -----------------------
    ckpt_path = os.path.join(output_dir, "best.pt")
    logger.info(f"Loading checkpoint from: {ckpt_path}")
    checkpoint = torch.load(ckpt_path, map_location=device)
    logger.info(f"Checkpoint keys: {list(checkpoint.keys())}")

    temperature = checkpoint.get("temperature", None)
    if temperature is not None:
        logger.info(f"Loaded temperature: {temperature}")

    # âœ… checkpoint í‚¤ ì´ë¦„: resp_state_dict / sleep_state_dict / ekg_state_dict
    model_resp.load_state_dict(checkpoint["resp_state_dict"])
    model_sleep.load_state_dict(checkpoint["sleep_state_dict"])
    model_ekg.load_state_dict(checkpoint["ekg_state_dict"])

    model_resp.eval()
    model_sleep.eval()
    model_ekg.eval()

    # -----------------------
    # ì„ë² ë”© ì €ì¥ ê²½ë¡œ
    # -----------------------
    path_to_save = os.path.join(output_dir, "eval_data")
    os.makedirs(path_to_save, exist_ok=True)
    logger.info(f"Embeddings will be saved to: {path_to_save}")

    # -----------------------
    # ê° splitë³„ë¡œ ì„ë² ë”© ì¶”ì¶œ
    # -----------------------
    for split in splits:
        logger.info(f"Processing split: {split}")
        dataloader = torch.utils.data.DataLoader(
            dataset[split],
            batch_size=batch_size,
            num_workers=num_workers,
            shuffle=False,
            drop_last=False,
        )

        emb = [[], [], []]  # resp, sleep, ekg

        with torch.no_grad():
            with tqdm.tqdm(total=len(dataloader), desc=f"Embeddings for {split}") as pbar:
                for (resp, sleep, ekg) in dataloader:
                    resp = resp.to(device, dtype=torch.float)
                    sleep = sleep.to(device, dtype=torch.float)
                    ekg = ekg.to(device, dtype=torch.float)

                    # ğŸ”¥ Sleep_Stages ì±„ë„ mismatch ì²˜ë¦¬
                    # checkpoint ê¸°ì¤€ in_channel_sleep(=5)ì¸ë°
                    # ì‹¤ì œ ë°ì´í„°ê°€ [B,4,T]ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš° dummy ì±„ë„ì„ ë’¤ì— ë¶™ì—¬ì„œ [B,5,T]ë¡œ ë§ì¶˜ë‹¤.
                    if sleep.dim() == 3 and sleep.size(1) != in_channel_sleep:
                        logger.warning(
                            f"Sleep channels mismatch: got {sleep.size(1)}, "
                            f"expected {in_channel_sleep}. Padding with zeros."
                        )
                        if sleep.size(1) < in_channel_sleep:
                            pad_channels = in_channel_sleep - sleep.size(1)
                            zeros = torch.zeros(
                                sleep.size(0),
                                pad_channels,
                                sleep.size(2),
                                device=sleep.device,
                                dtype=sleep.dtype,
                            )
                            sleep = torch.cat([sleep, zeros], dim=1)
                        else:
                            # í˜¹ì‹œ ì±„ë„ì´ ë” ë§ìœ¼ë©´ ì˜ë¼ì„œ ë§ì¶¤
                            sleep = sleep[:, :in_channel_sleep, :]

                    emb[0].append(
                        torch.nn.functional.normalize(model_resp(resp)).cpu()
                    )
                    emb[1].append(
                        torch.nn.functional.normalize(model_sleep(sleep)).cpu()
                    )
                    emb[2].append(
                        torch.nn.functional.normalize(model_ekg(ekg)).cpu()
                    )

                    pbar.update()

        # ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë“¤ì–´ ìˆëŠ” í…ì„œë“¤ì„ concat
        emb = list(map(torch.concat, emb))  # [resp_emb, sleep_emb, ekg_emb]

        dataset_prefix = os.path.splitext(dataset_file)[0]
        save_path = os.path.join(
            path_to_save, f"{dataset_prefix}_{split}_emb.pickle"
        )

        logger.info(f"Saving embeddings for {split} to: {save_path}")
        with open(save_path, "wb") as f:
            pickle.dump(emb, f)


if __name__ == "__main__":
    generate_eval_embed()
